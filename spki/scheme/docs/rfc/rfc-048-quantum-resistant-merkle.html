<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>RFC-048: Quantum-Resistant Merkle Trees</title>
  <link rel="stylesheet" href="rfc.css">
</head>
<body>
<h1>RFC-048: Quantum-Resistant Merkle Trees</h1>
<dl class="metadata">
</dl>
<hr>
<section>
<h2>Abstract</h2>
<p>SHA-512 won't survive. Grover's algorithm halves the effective security - 256 bits becomes 128. For the wilderness of mirrors to endure the quantum winter, we need quantum-resistant Merkle trees. This RFC specifies the transition from flat SHA-512 hashes to tree-structured SHAKE256 hashes.</p>
</section>
<section>
<h2>The Problem</h2>
<p>Current cyberspace object identity:</p>
<pre>
sha512(content) â†’ 64 bytes â†’ object address
</pre>
<p>Against a quantum computer with Grover's algorithm: - Classical security: 256 bits - Quantum security: 128 bits (square root)</p>
<p>128 bits may be acceptable for some threat models, but cyberspace is built to last. The Library of Alexandria burned once. We won't let quantum computers burn it again.</p>
</section>
<section>
<h2>The Solution: Merkle Trees</h2>
<p>Instead of hashing content as a flat blob, structure it as a tree:</p>
<pre>
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Merkle Root   â”‚  â† Object identity
                    â”‚  shake256(...)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚              â”‚              â”‚
         â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
         â”‚ Node 0  â”‚    â”‚ Node 1  â”‚    â”‚ Node 2  â”‚
         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
              â”‚              â”‚              â”‚
        â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
        â”‚           â”‚  â”‚           â”‚  â”‚           â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â” ...
    â”‚Chunk 0â”‚ â”‚Chunk 1â”‚ â”‚Chunk 2â”‚ â”‚Chunk 3â”‚ â”‚Chunk 4â”‚
    â”‚ 4 KB  â”‚ â”‚ 4 KB  â”‚ â”‚ 4 KB  â”‚ â”‚ 4 KB  â”‚ â”‚ 4 KB  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜
</pre>
<p>Benefits:</p>
<p>1. Incremental updates - Change one chunk, rehash one branch 2. Selective disclosure - Prove a chunk exists without revealing siblings 3. Streaming verification - Verify chunks as they arrive 4. Parallelizable - Hash chunks concurrently 5. Quantum-resistant - SHAKE256 at every node</p>
</section>
<section>
<h2>Hash Function: SHAKE256</h2>
<p>SHAKE256 is an extendable-output function (XOF) from the SHA-3 (Keccak) family.</p>
<p>Why SHAKE256:</p>
<table>
<tr><th>Property </th><th>Value </th></tr>
<tr><td>Security level </td><td>256-bit classical, 128-bit quantum </td></tr>
<tr><td>Output length </td><td>Variable (we use 256 bits) </td></tr>
<tr><td>Construction </td><td>Sponge (different from SHA-2's Merkle-DamgÃ¥rd) </td></tr>
<tr><td>Standard </td><td>NIST FIPS 202 </td></tr>
<tr><td>Used by </td><td>SPHINCS+ (post-quantum signatures) </td></tr>
<tr><td>In libsodium </td><td>No, but in OpenSSL, libgcrypt </td></tr>
</table>
<p>Alternative: BLAKE3</p>
<table>
<tr><th>Property </th><th>Value </th></tr>
<tr><td>Security level </td><td>256-bit classical, 128-bit quantum </td></tr>
<tr><td>Output length </td><td>Variable </td></tr>
<tr><td>Construction </td><td>Merkle tree internally </td></tr>
<tr><td>Speed </td><td>Very fast, SIMD optimized </td></tr>
<tr><td>Standard </td><td>Not NIST, but widely trusted </td></tr>
</table>
<p>BLAKE3 is faster and already tree-structured, but SHAKE256 has NIST blessing. We support both.</p>
</section>
<section>
<h2>Object Format</h2>
<h3>Current (Legacy)</h3>
<pre class="language-scheme">
(object
  (hash "sha512:3a7bd3e2c4f8...")
  (size 1048576)
  (content ...))
</pre>
<h3>Quantum-Resistant</h3>
<pre class="language-scheme">
(object
  (merkle-root "shake256:7f4a2b9c...")
  (hash-algorithm "shake256")          ; or "blake3"
  (tree-params
    (chunk-size 4096)                  ; 4 KB chunks
    (fanout 16)                        ; Children per node
    (depth 4))                         ; Tree depth
  (size 1048576)
  (content ...))
</pre>
<h3>Transition Period (Dual Hash)</h3>
<pre class="language-scheme">
(object
  (hash "sha512:3a7bd3e2c4f8...")           ; Legacy - for old clients
  (merkle-root "shake256:7f4a2b9c...")      ; Quantum-resistant
  (hash-algorithm "shake256")
  (tree-params
    (chunk-size 4096)
    (fanout 16)
    (depth 4))
  (size 1048576)
  (content ...))
</pre>
<p>Old clients use hash. New clients use merkle-root. Both verify the same content.</p>
</section>
<section>
<h2>Tree Construction</h2>
<h3>Algorithm</h3>
<pre class="language-scheme">
(define (merkle-hash content algorithm chunk-size fanout)
  "Build Merkle tree, return root hash"

  ;; 1. Split content into chunks
  (let* ((chunks (chunk-content content chunk-size))

         ;; 2. Hash each chunk (leaves)
         (leaves (map (lambda (chunk)
                        (hash algorithm chunk))
                      chunks))

         ;; 3. Build tree bottom-up
         (root (build-tree leaves fanout algorithm)))

    root))

(define (build-tree nodes fanout algorithm)
  "Combine nodes into parent nodes until one root remains"
  (if (&lt;= (length nodes) 1)
      (car nodes)
      (let ((parents (map (lambda (group)
                            (hash algorithm (apply append group)))
                          (partition nodes fanout))))
        (build-tree parents fanout algorithm))))
</pre>
<h3>Node Hashing</h3>
<p>Each internal node hashes the concatenation of its children:</p>
<pre>
nodehash = shake256(child0 || child1 || ... || childn)
</pre>
<p>For leaves:</p>
<pre>
leafhash = shake256(chunkdata)
</pre>
<h3>Canonical Parameters</h3>
<table>
<tr><th>Parameter </th><th>Default </th><th>Notes </th></tr>
<tr><td>chunk-size </td><td>4096 </td><td>4 KB, filesystem-friendly </td></tr>
<tr><td>fanout </td><td>16 </td><td>Balance between depth and width </td></tr>
<tr><td>algorithm </td><td>shake256 </td><td>NIST approved </td></tr>
<tr><td>output-length </td><td>32 </td><td>256 bits </td></tr>
</table>
</section>
<section>
<h2>Proofs</h2>
<h3>Inclusion Proof</h3>
<p>Prove a chunk is part of an object without revealing other chunks:</p>
<pre class="language-scheme">
(inclusion-proof
  (merkle-root "shake256:7f4a2b9c...")
  (chunk-index 42)
  (chunk-hash "shake256:abc123...")
  (path
    ((sibling "shake256:def456..." position left)
     (sibling "shake256:789abc..." position right)
     (sibling "shake256:012def..." position left))))
</pre>
<p>Verifier reconstructs path to root:</p>
<pre>
chunk_hash â†’ combine with sibling â†’ ... â†’ must equal merkle-root
</pre>
<h3>Exclusion Proof</h3>
<p>Prove a chunk does NOT exist (for sparse objects):</p>
<pre class="language-scheme">
(exclusion-proof
  (merkle-root "shake256:7f4a2b9c...")
  (chunk-index 999)
  (boundary-left 998 "shake256:left...")
  (boundary-right 1000 "shake256:right...")
  (path ...))
</pre>
</section>
<section>
<h2>Streaming Verification</h2>
<p>Large objects can be verified chunk-by-chunk as they stream:</p>
<pre class="language-scheme">
(define (verify-stream merkle-root chunk-size)
  "Return a verifier that checks chunks as they arrive"
  (let ((received-chunks '())
        (verified-nodes (make-hash-table)))

    (lambda (chunk-index chunk-data proof)
      ;; Verify this chunk against the proof
      (let ((chunk-hash (shake256 chunk-data)))
        (if (verify-inclusion-proof merkle-root chunk-index chunk-hash proof)
            (begin
              (cache-verified-node! verified-nodes chunk-index chunk-hash)
              #t)
            #f)))))
</pre>
<p>You don't need the whole object to start verifying. Each chunk carries its own proof.</p>
</section>
<section>
<h2>The Forest</h2>
<p>The soup becomes a forest of Merkle trees:</p>
<pre>
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    THE FOREST (formerly soup)                    â”‚
â”‚                                                                  â”‚
â”‚     ğŸŒ² obj    ğŸŒ² obj       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      ğŸŒ² obj       â”‚
â”‚          ğŸŒ² obj           â”‚â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚           ğŸŒ² obj  â”‚
â”‚    ğŸŒ² obj          ğŸŒ² obj â”‚â–‘â–‘â–‘  REALM  â–‘â–‘â–‘â–‘â–‘â”‚    ğŸŒ² obj         â”‚
â”‚         ğŸŒ² obj            â”‚â–‘â–‘â–‘ (island) â–‘â–‘â–‘â–‘â”‚         ğŸŒ² obj    â”‚
â”‚   ğŸŒ² obj       ğŸŒ² obj     â”‚â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚  ğŸŒ² obj           â”‚
â”‚        ğŸŒ² obj             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       ğŸŒ² obj      â”‚
â”‚                                                                  â”‚
â”‚   Each object a tree. Each tree quantum-hardened.               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</pre>
<p>Objects are trees. The wilderness of mirrors becomes a forest. Agents navigate between trees, climbing branches, verifying paths. The capability chain is still their thread - but now the mirrors are structured.</p>
</section>
<section>
<h2>Migration</h2>
<h3>Phase 1: Dual Hash (Now â†’ Q-Day - 5 years)</h3>
<p>All new objects get both hashes. Old objects rehashed on access.</p>
<pre class="language-scheme">
(define (store-object content)
  (let ((legacy-hash (sha512 content))
        (merkle-root (merkle-hash content 'shake256 4096 16)))
    (vault-store
      `(object
        (hash ,(string-append "sha512:" legacy-hash))
        (merkle-root ,(string-append "shake256:" merkle-root))
        ...))))
</pre>
<h3>Phase 2: Merkle Primary (Q-Day - 5 years â†’ Q-Day)</h3>
<p>Merkle root becomes the canonical address. SHA-512 kept for compatibility.</p>
<h3>Phase 3: Legacy Sunset (Q-Day â†’ Q-Day + 2 years)</h3>
<p>SHA-512 hashes deprecated. Only Merkle roots used for addressing.</p>
<h3>Phase 4: Pure Quantum-Resistant (Q-Day + 2 years â†’)</h3>
<p>SHA-512 hashes removed from new objects. Legacy objects retain both for historical verification.</p>
</section>
<section>
<h2>Performance</h2>
<table>
<tr><th>Operation </th><th>SHA-512 (flat) </th><th>SHAKE256 (Merkle) </th><th>Notes </th></tr>
<tr><td>Hash 1 MB </td><td>2 ms </td><td>3 ms </td><td>Slightly slower </td></tr>
<tr><td>Hash 1 GB </td><td>2000 ms </td><td>2500 ms </td><td>Tree overhead </td></tr>
<tr><td>Update 4 KB in 1 GB </td><td>2000 ms </td><td>15 ms </td><td>Merkle wins </td></tr>
<tr><td>Prove inclusion </td><td>N/A </td><td>0.1 ms </td><td>New capability </td></tr>
<tr><td>Streaming verify </td><td>N/A </td><td>Per-chunk </td><td>New capability </td></tr>
</table>
<p>The overhead is small. The benefits are large.</p>
</section>
<section>
<h2>Security Considerations</h2>
<h3>Grover's Algorithm</h3>
<p>Grover's algorithm provides quadratic speedup for searching: - SHA-512: 2^256 â†’ 2^128 quantum operations - SHAKE256-256: 2^256 â†’ 2^128 quantum operations</p>
<p>128-bit quantum security is considered sufficient for the foreseeable future.</p>
<h3>Second Preimage Resistance</h3>
<p>Finding another input that hashes to the same tree requires: - Classical: 2^256 operations - Quantum: 2^128 operations (Grover)</p>
<h3>Tree Structure Attacks</h3>
<p>The Merkle tree structure must prevent: - Length extension: SHAKE256 immune (sponge construction) - Subtree collision: Domain separation in node hashing - Malleability: Canonical serialization required</p>
<h3>Implementation</h3>
<pre class="language-scheme">
;; Domain separation for nodes vs leaves
(define (hash-leaf algorithm chunk)
  (hash algorithm (bytevector-append #u8(0) chunk)))

(define (hash-node algorithm children)
  (hash algorithm (bytevector-append #u8(1) (apply bytevector-append children))))
</pre>
<p>The 0x00 prefix for leaves and 0x01 for nodes prevents a leaf from being interpreted as a node.</p>
</section>
<section>
<h2>Invariants</h2>
<pre>
M1. Object identity is Merkle root
    id(o) = merkle-root(shake256, chunks(o))

M2. Any chunk is provable
    chunk(o,i) â†’ âˆƒproof: verify(root(o), i, chunk, proof)

M3. Tree structure is canonical
    tree(content, params) is deterministic

M4. Dual hashes are consistent
    sha512(content) â†” merkle-root(content) verify same content

M5. Migration preserves identity
    old-objects retain verifiable legacy hashes
</pre>
</section>
<section>
<h2>References</h2>
<p>1. NIST FIPS 202 - SHA-3 Standard (SHAKE256) 2. BLAKE3 specification - https://github.com/BLAKE3-team/BLAKE3 3. Merkle, R., "A Digital Signature Based on a Conventional Encryption Function", 1987 4. Grover, L., "A Fast Quantum Mechanical Algorithm for Database Search", 1996 5. RFC-040 - Cyberspace Security Architecture</p>
</section>
<section>
<h2>Changelog</h2>
<ul>
<li>2026-01-08</li>
<li>Initial draft</li>
</ul>
</section>
</body>
</html>
