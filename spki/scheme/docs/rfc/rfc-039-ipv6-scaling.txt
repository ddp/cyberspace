RFC-039: Scaling Architecture for IPv6


------------------------------------------------------------------------------

------------------------------------------------------------------------------
ABSTRACT
------------------------------------------------------------------------------

This RFC defines the architectural changes required to scale Cyberspace from a
git-backed prototype to a native distributed system capable of operating at
IPv6 scale (billions of realms, exabytes of content). Git becomes an export
format; the vault becomes the source of truth.


------------------------------------------------------------------------------
TERMINOLOGY
------------------------------------------------------------------------------

Realm: A node's place in cyberspace - its vault, principal, capabilities, and
objects. Each realm is sovereign: local-first, controlled by its operator.
Realms federate by choice, sharing objects according to trust relationships.

Vault: The local content-addressed object store (.vault/). The vault IS the
realm's storage - all objects, catalogs, audit trails, and configuration live
here.

Principal: A node's cryptographic identity (Ed25519 public key). The principal
identifies the realm to peers and signs its objects.

At IPv6 scale, cyberspace consists of billions of realms, each occupying its
own address space, each sovereign, each choosing what to share and with whom.


------------------------------------------------------------------------------
MOTIVATION
------------------------------------------------------------------------------

Git served as an excellent prototype substrate: - Content-addressed objects
(proof of concept) - Merkle tree integrity (validates the model) - Ubiquitous
tooling (bootstrap adoption)

Git cannot scale to IPv6: - Full history on every clone - Repository as
replication unit (too coarse) - SHA-1 (cryptographically broken) - No native
federation or discovery - Merge semantics are wrong model

The internet has 2^128 addresses. Cyberspace should use them.


------------------------------------------------------------------------------
DESIGN PRINCIPLES
------------------------------------------------------------------------------


    1. Objects, not repositories
    2. Pull, not push
    3. Lazy, not eager
    4. Local-first, federate-second
    5. Trust math, not infrastructure


------------------------------------------------------------------------------
CONTENT-ADDRESSED OBJECT STORE
------------------------------------------------------------------------------


Storage Model
-------------


    .vault/
      objects/
        sha512-a1b2c3.../    # First 8 chars as directory
          a1b2c3d4e5f6...    # Full hash as filename (S-expression)
      catalog/
        manifest.sexp        # Vault catalog object
        bloom.sexp           # Bloom filter object
        indices/             # Secondary index objects
          by-signer.sexp
          by-type.sexp
      chunks/
        sha512-xxxx/         # Chunked large objects
      audit/
        head.sexp            # Current audit chain head
        chain/               # Audit entries (hash-addressed)


Object Format
-------------


    (cyberspace-object
      (version 1)
      (type blob|tree|manifest|cert|audit)
      (size 1048576)
      (compression zstd|none)
      (hash "sha512:a1b2c3...")
      (chunks ("sha512:..." "sha512:..." ...))  ; If chunked
      (signature "ed25519:...")
      (timestamp 1736300000))


Chunking Strategy
-----------------

Large objects split at content-defined boundaries (Rabin fingerprinting):


    Target chunk: 64 KB (Starlink-optimized)
    Min chunk:    16 KB
    Max chunk:   256 KB
    Benefits:
      - Deduplication across objects
      - Partial sync (fetch only missing chunks)
      - Resumable transfers
      - Efficient diff


Hash Function
-------------


    SHA-512 everywhere.
    Not SHA-256: We have the bits, use them.
    Not SHA-1: Broken.
    Not BLAKE3: Less analyzed, marginal speed gain irrelevant at network latency.
    SHA-512 is:
      - FIPS certified (GovCloud path)
      - 50 years of cryptanalysis
      - Hardware accelerated
      - Already in use (audit trail, signatures)


------------------------------------------------------------------------------
CATALOG AND QUERY
------------------------------------------------------------------------------

The soup IS the catalog. No SQL. Objects are S-expressions, queries are
pattern matching.


The Soup Query Model
--------------------


    ;; Find objects by pattern
    (soup-query
      '(cyberspace-object
        (type blob)
        (signer "ed25519:alice...")
        ?rest))                        ; Match any object signed by Alice
    ;; Find by hash (direct lookup)
    (soup-fetch "sha512:a1b2c3...")    ; O(1) content-addressed
    ;; Find by type
    (soup-query '(cyberspace-object (type cert) ?rest))
    ;; Find by time range
    (soup-query-range
      type: 'audit
      from: 1736000000
      to:   1736100000)
    ;; Cursor-based iteration for large result sets
    (soup-cursor
      '(cyberspace-object (type ?) ?rest)
      batch: 100)


Object Catalog
--------------

The catalog is itself an object in the soup - a manifest of what the vault
contains:


    (vault-catalog
      (version 1)
      (realm "ed25519:principal...")
      (object-count 150000)
      (types
        (blob 100000)
        (tree 30000)
        (cert 15000)
        (audit 5000))
      (bloom-filter #${...})           ; Fast existence check
      (updated 1736400000))


Bloom Filter
------------

Fast existence check before network round-trip:


    (define (soup-maybe-contains? hash)
      "Check bloom filter - false means definitely not, true means maybe"
      (let ((catalog (soup-fetch-catalog)))
        (bloom-test (catalog-bloom catalog) hash)))
    ;; Bloom parameters
    (bloom-filter
      (capacity 10000000)              ; 10M objects
      (false-positive 0.001)           ; 0.1% FP rate
      (bits #${...}))


Audit Trail
-----------

The audit trail is a hash-chain of objects in the soup:


    (audit-entry
      (sequence 12345)
      (timestamp 1736300000)
      (lamport 67890)
      (actor "ed25519:subject...")
      (action (read "sha512:object..."))
      (previous "sha512:prev-entry...")  ; Chain link
      (signature "ed25519:auditor..."))
    ;; Query audit by walking the chain
    (define (audit-query actor from-seq)
      "Walk audit chain, filter by actor"
      (soup-chain-walk
        start: (audit-head)
        filter: (lambda (entry)
                  (equal? (entry-actor entry) actor))
        from: from-seq))


Secondary Indices
-----------------

For queries that can't use content-addressing, the soup maintains lightweight
indices as objects:


    (soup-index
      (name "by-signer")
      (key-type principal)
      (entries
        (("ed25519:alice..." ("sha512:obj1" "sha512:obj2" ...))
         ("ed25519:bob..." ("sha512:obj3" "sha512:obj4" ...)))))
    (soup-index
      (name "by-type")
      (key-type symbol)
      (entries
        ((blob ("sha512:..." "sha512:..." ...))
         (cert ("sha512:..." "sha512:..." ...))
         (audit ("sha512:..." "sha512:..." ...)))))

Indices are rebuilt on demand, not authoritative - the soup is truth.


------------------------------------------------------------------------------
DISCOVERY AND ROUTING
------------------------------------------------------------------------------


Realm Identity
--------------

Each realm has a principal (Ed25519 public key). This IS its identity:


    (realm-identity
      (principal "ed25519:a1b2c3...")
      (addresses                          ; Where to reach this realm
        (ipv6 "2001:db8::1" port: 7777)
        (ipv4 "192.0.2.1" port: 7777)     ; Legacy
        (onion "xxxx.onion" port: 7777))  ; Tor
      (role witness)
      (capabilities (storage-gb 1000) (bandwidth-mbps 100))
      (signature "ed25519:..."))


Peer Discovery
--------------

Bootstrap:


    (bootstrap-peers
      ("ed25519:official1..." "bootstrap.cyberspace.org")
      ("ed25519:official2..." "bootstrap2.cyberspace.org"))

Gossip Protocol:


    1. Realm joins, contacts bootstrap peer
    2. Receives partial peer list (random subset)
    3. Contacts those peers, exchanges lists
    4. Epidemic spread: O(log n) rounds to reach all realms
    5. Periodic refresh (every 5 min on Starlink-friendly schedule)

Distributed Hash Table (Future):


    Kademlia-style routing:
      - XOR distance metric on principal hashes
      - O(log n) lookups
      - Realms responsible for nearby hash ranges
      - Natural load balancing


Content Discovery
-----------------


    ;; "Who has this hash?"
    (content-locate "sha512:a1b2c3...")
    ;; Returns list of peers claiming to have it:
    (("ed25519:peer1..." (latency-ms 50) (role full))
     ("ed25519:peer2..." (latency-ms 200) (role witness))
     ("ed25519:peer3..." (latency-ms 600) (role archiver)))
    ;; Fetch from best candidate
    (content-fetch "sha512:a1b2c3..." from: "ed25519:peer1...")


------------------------------------------------------------------------------
TRANSPORT PROTOCOL
------------------------------------------------------------------------------


End-to-End Encryption
---------------------

All network traffic is encrypted. The OS and network are not trusted.


    (cyberspace-message
      (version 1)
      (from "ed25519:sender...")
      (to "ed25519:recipient...")        ; Or broadcast key
      (ephemeral "x25519:...")           ; One-time key (PFS)
      (nonce #${24-bytes})               ; Random nonce
      (ciphertext #${...})               ; NaCl box: X25519 + XSalsa20-Poly1305
      (signature "ed25519:..."))         ; Sign the ciphertext

Encryption scheme: NaCl crypto_box (libsodium) - Key agreement: X25519
(Curve25519 ECDH) - Cipher: XSalsa20-Poly1305 - Perfect forward secrecy:
ephemeral keys per message

Decrypted payload:


    (plaintext-payload
      (type request|response|announce|gossip)
      (nonce 12345678)                   ; Replay protection
      (timestamp 1736300000)
      (body ...))

Broadcast messages use a shared group key or are signed-only (announcements of
public objects).


Wire Format (Encrypted)
-----------------------


    ;; Sender encrypts
    (define (seal-message payload recipient-pubkey sender-keypair)
      (let ((ephemeral (x25519-keypair))
             (shared (x25519-shared (ephemeral-secret ephemeral) recipient-pubkey))
             (nonce (random-bytes 24))
             (ciphertext (crypto-box payload nonce shared)))
        `(cyberspace-message
          (version 1)
          (from ,(keypair-public sender-keypair))
          (to ,recipient-pubkey)
          (ephemeral ,(ephemeral-public ephemeral))
          (nonce ,nonce)
          (ciphertext ,ciphertext)
          (signature ,(sign-message ciphertext sender-keypair)))))
    ;; Recipient decrypts
    (define (open-message msg recipient-keypair)
      (let ((shared (x25519-shared (keypair-secret recipient-keypair)
                                    (message-ephemeral msg)))
             (plaintext (crypto-box-open (message-ciphertext msg)
                                         (message-nonce msg)
                                         shared)))
        (and (verify-signature msg (message-from msg))
             plaintext)))


Request Types
-------------


    ;; Existence check
    (have? ("sha512:..." "sha512:..." ...))
    ;; Response: (have ("sha512:..." "sha512:...") missing ("sha512:..."))
    ;; Fetch object
    (fetch "sha512:...")
    ;; Response: (object ...)
    ;; Fetch chunk range
    (fetch-chunks "sha512:..." start: 5 count: 10)
    ;; Response: (chunks ...)
    ;; Peer list exchange
    (peers? limit: 50)
    ;; Response: (peers ...)
    ;; Announce new content
    (announce ("sha512:..." "sha512:..."))
    ;; Response: (ack)


Transport Bindings
------------------


    Native:     UDP/IPv6, port 7777 (primary)
    Fallback:   TCP/IPv6, port 7777 (firewalls)
    Legacy:     TCP/IPv4, port 7777 (transition)
    Stealth:    Tor onion service (censorship resistance)
    Offline:    USB drive, file copy (sneakernet)
    Export:     Git bundle (GitHub compatibility)


Starlink Optimization
---------------------


    (transport-config
      (mode satellite)
      (batch-window-ms 500)        ; Aggregate small messages
      (chunk-size-kb 64)           ; Match MTU
      (retry-strategy exponential)
      (max-in-flight 10)           ; Parallelism
      (keepalive-sec 300))         ; 5 min, not 30 sec


------------------------------------------------------------------------------
SYNCHRONIZATION PROTOCOL
------------------------------------------------------------------------------


Lazy Sync (Default)
-------------------


    Node A                              Node B
       |                                   |
       |----(have? [h1, h2, h3])---------->|
       |<---(have [h1, h3] missing [h2])---|
       |----(fetch h2)-------------------->|
       |<---(object h2 ...)----------------|
       |                                   |
    No coordination. No locks. No leader.


Crdt-Style Convergence
----------------------

Objects are immutable and content-addressed. No conflicts possible at object
level.

Manifests (collections of objects) use: - Lamport timestamps for ordering -
Last-writer-wins with principal tiebreaker - Or: union (add-only sets)


    (manifest
      (name "library")
      (version (lamport 42) (principal "ed25519:..."))
      (entries
        ("rfc-001" "sha512:...")
        ("rfc-002" "sha512:...")
        ...))


Merkle Sync
-----------

Efficient diff for large manifests:


             root
            /    \
          h1      h2
         /  \    /  \
        a    b  c    d
    Exchange root hash.
    If different, recurse on children.
    O(log n) round trips to find diff.


------------------------------------------------------------------------------
FEDERATION AT SCALE
------------------------------------------------------------------------------


Cluster Topology
----------------


                        ┌─────────────────────────────────────┐
                        │         COORDINATOR CLUSTER         │
                        │  (3-7 nodes, Byzantine consensus)   │
                        └────────────────┬────────────────────┘
                                         │
              ┌──────────────────────────┼──────────────────────────┐
              │                          │                          │
        ┌─────▼─────┐             ┌──────▼─────┐             ┌──────▼─────┐
        │   FULL    │             │   FULL     │             │    FULL    │
        │  NODES    │             │   NODES    │             │   NODES    │
        └─────┬─────┘             └─────┬──────┘             └─────┬──────┘
              │                         │                          │
        ┌─────▼─────┐             ┌─────▼──────┐             ┌─────▼──────┐
        │ WITNESSES │             │ WITNESSES  │             │ WITNESSES  │
        │ ARCHIVERS │             │ ARCHIVERS  │             │ ARCHIVERS  │
        │   EDGES   │             │   EDGES    │             │   EDGES    │
        └───────────┘             └────────────┘             └────────────┘
    Coordinators: Rare, high-capability realms, run consensus
    Full: Common realms, replicate everything, serve content
    Witnesses: Abundant realms, verify and store, passive sync
    Archivers: Cold storage realms, batch sync
    Edges: Read-only realms, intermittent, mobile


Partition Tolerance
-------------------


    Network splits → clusters diverge → clusters converge on reconnect
    No data loss (content-addressed)
    No conflicts (immutable objects)
    Audit trails merge (union of entries, Lamport ordering)
    Manifests resolve (LWW or union based on type)


------------------------------------------------------------------------------
GIT AS EXPORT FORMAT
------------------------------------------------------------------------------


The Transition
--------------


    Phase 1 (Now):      Git is source of truth, vault is cache
    Phase 2 (Next):     Vault is source of truth, git is export
    Phase 3 (Future):   Git optional, purely for GitHub presence


Export Process
--------------


    (git-export
      from: ".vault"
      to: "/tmp/cyberspace-export"
      format: 'git-repo)
    ;; Creates standard git repo from vault contents
    ;; For publishing to GitHub, GitLab, etc.


Import Process
--------------


    (git-import
      from: "https://github.com/ddp/cyberspace.git"
      to: ".vault")
    ;; Extracts objects from git, stores in vault
    ;; Discards git history, keeps content


------------------------------------------------------------------------------
SECURITY AT SCALE
------------------------------------------------------------------------------


Sybil Resistance
----------------

Problem: Attacker creates many fake nodes to dominate network.

Mitigations: 1. Stake-weighted voting (not proof-of-work, just reputation) 2.
Web of trust - new nodes introduced by existing trusted nodes 3. Rate limiting
- bound resources per principal 4. Coordinator consensus - Byzantine-resistant
core


Eclipse Attack Resistance
-------------------------

Problem: Attacker isolates a node by controlling all its peers.

Mitigations: 1. Diverse bootstrap - multiple independent entry points 2.
Random peer selection - can't predict who you'll connect to 3. Peer rotation -
periodically reconnect to new peers 4. Out-of-band verification - publish peer
lists via DNS, blockchain, etc.


Denial of Service
-----------------

Problem: Attacker floods network with junk.

Mitigations: 1. Proof of work on announcements (small, CPU cost) 2. Rate
limiting per principal 3. Reputation scoring - misbehaving peers deprioritized
4. Content validation - reject malformed objects immediately


------------------------------------------------------------------------------
IMPLEMENTATION PHASES
------------------------------------------------------------------------------


Phase 1: Native Object Store
----------------------------

- Implement .vault/objects/ storage - Soup catalog and query - Keep git for
development workflow


Phase 2: Local-First Sync
-------------------------

- Direct node-to-node protocol - have?/fetch message types - UDP transport
with TCP fallback


Phase 3: Discovery
------------------

- Gossip peer exchange - Bootstrap nodes - Bloom filters for content location


Phase 4: Scale Testing
----------------------

- 100 nodes - 1000 nodes - 10000 nodes - Measure: latency, convergence time,
bandwidth


Phase 5: Git Deprecation
------------------------

- Vault as source of truth - Git export for compatibility - Remove git
dependency from core operations


------------------------------------------------------------------------------
METRICS AND MONITORING
------------------------------------------------------------------------------


    (node-metrics)
    ;; Returns:
    ((objects-stored 150000)
     (objects-size-gb 50)
     (peers-known 500)
     (peers-connected 20)
     (sync-lag-seconds 30)
     (bandwidth-in-mbps 10)
     (bandwidth-out-mbps 5)
     (requests-per-second 100)
     (errors-per-second 0.1))


------------------------------------------------------------------------------
REFERENCES
------------------------------------------------------------------------------

1. RFC-010: Federation Protocol 2. RFC-016: Lazy Clustering 3. RFC-037: Node
Roles and Capabilities 4. Maymounkov, P. (2002). Kademlia: A Peer-to-peer
Information System 5. Rabin, M. (1981). Fingerprinting by Random Polynomials
6. IPFS Whitepaper (2014) 7. Shapiro, M. (2011). Conflict-Free Replicated Data
Types


------------------------------------------------------------------------------
CHANGELOG
------------------------------------------------------------------------------

- 2026-01-07 - Initial draft

------------------------------------------------------------------------------
