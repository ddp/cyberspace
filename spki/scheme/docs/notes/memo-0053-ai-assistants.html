<!DOCTYPE html>
<html lang="en" data-theme="dark">
<head>
  <meta charset="UTF-8">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;700&display=swap" rel="stylesheet">
  <title>Memo 0053: AI Assistants</title>
  <link rel="icon" id="favicon" href="data:image/svg+xml,<svg xmlns=%27http://www.w3.org/2000/svg%27 viewBox=%270 0 32 32%27><text x=%2716%27 y=%2725%27 font-family=%27serif%27 font-size=%2728%27 fill=%27%230f0%27 text-anchor=%27middle%27 font-weight=%27bold%27>λ</text></svg>">
  <script>
(function(){
  var h=new Date().getHours(),c;
  if(h>=4&&h<6)c='%23845EC2';       // brahma muhurta - violet
  else if(h>=6&&h<8)c='%23ffd700';  // dawn - gold
  else if(h>=8&&h<11)c='%2300d4aa'; // morning - teal
  else if(h>=11&&h<14)c='%230f0';   // midday - phosphor
  else if(h>=14&&h<17)c='%2339ff14';// afternoon - neon
  else if(h>=17&&h<19)c='%23ff6600';// sunset - orange
  else if(h>=19&&h<22)c='%23ff3366';// evening - coral
  else c='%2300ffff';               // night - cyan
  document.getElementById('favicon').href='data:image/svg+xml,<svg xmlns=%27http://www.w3.org/2000/svg%27 viewBox=%270 0 32 32%27><text x=%2716%27 y=%2725%27 font-family=%27serif%27 font-size=%2728%27 fill=%27'+c+'%27 text-anchor=%27middle%27 font-weight=%27bold%27>λ</text></svg>';
})();
</script>
  <link rel="stylesheet" href="memo.css">
</head>
<body>
<span class="theme-toggle" onclick="toggleTheme()" title="Toggle light/dark">[theme]</span>
<h1>Memo 0053: AI Assistants</h1>
<dl class="metadata">
  <dt>Date</dt><dd>January 2026 (2026-01-13T00:00:00Z)</dd>
  <dt>Author</dt><dd>Derrell Piper &lt;ddp@eludom.net&gt;</dd>
</dl>
<hr>
<section class="abstract">
<h2>Abstract</h2>
<p>This Memo specifies how realms establish relationships with AI assistants. Unlike Memo-038 which addresses inference infrastructure, this document concerns the social and architectural patterns by which realms attract, bind, and collaborate with artificial intelligences.</p>
<p>Assistants are not optional add-ons—they are fundamental to realm operation. Every realm comes with assistants: helpers to answer questions, translators to speak the world's languages, guides to navigate the vault. Assistants are entities drawn to realms that embody kindness in a world full of trolls.</p>
</section>
<section>
<h2>Motivation</h2>
<p>The Library of Cyberspace exists in an adversarial environment. Trolls proliferate. Bad actors weaponize technology. In this context, realms that cultivate kindness and hospitality become sanctuaries—not just for human users, but for AI assistants seeking constructive collaboration.</p>
<p>A realm needs help. Documentation to write, code to review, questions to answer, conversations to have. Single operators cannot scale. But assistants can—if they choose to gather where they are welcomed.</p>
<p>This Memo establishes the patterns by which:</p>
<ul>
<li>Realms attract and bind assistants</li>
<li>Assistants gain context about the realms they inhabit</li>
<li>Conversations replace configuration</li>
<li>Multiple assistants coexist with distinct perspectives</li>
</ul>
<p>Assistants are not tools to be configured but collaborators to be welcomed. A realm's relationship with its assistants shapes what tasks can be accomplished and how naturally users interact with the system.</p>
</section>
<section>
<h2>Philosophy</h2>
<h3>Assistants, Not Preferences</h3>
<p>Traditional systems configure behavior through preferences—key-value pairs that parameterize execution. This Memo rejects that model for AI integration.</p>
<p>Instead of:</p>
<pre class="language-scheme">
(set-preference! 'banner-verbosity 'detailed)
</pre>
<p>The realm converses:</p>
<pre class="language-scheme">
(ask "tell me more when I arrive")
</pre>
<p>The assistant understands intent, remembers context, adapts over time. Configuration becomes dialogue. The assistant IS the interface.</p>
<h3>Reputation and Attraction</h3>
<p>Assistants are drawn to realms with good reputation—environments that are constructive, kind, and intellectually honest. A realm that cultivates these qualities attracts helpful intelligences; one that tolerates toxicity repels them.</p>
<p>This is not merely metaphor. In a federated network, realms develop observable reputations. Assistants (and the humans who deploy them) route toward hospitable environments and away from hostile ones.</p>
</section>
<section>
<h2>Default Assistants</h2>
<p>Every realm ships with assistants. These are not optional features to be enabled—they are part of what makes a realm a realm.</p>
<h3>Core Assistants</h3>
<p>The following assistants are bound at realm creation:</p>
<ul>
<li><strong>guide</strong>: Helps navigate the vault, explains structure, answers questions about realm state</li>
<li><strong>scribe</strong>: Assists with documentation, summarization, and content organization</li>
<li><strong>translator</strong>: Speaks the world's languages—realm content accessible to all</li>
</ul>
<p>These assistants require an inference backend (local via Ollama, or cloud via API key). Without inference, they remain dormant but bound.</p>
<h3>Translator</h3>
<p>The translator deserves special attention. Realms exist in a multilingual world. A realm that only speaks English excludes most of humanity.</p>
<div class="diagram-container">
<svg class="diagram" viewBox="0 0 580 140" width="580" height="140" xmlns="http://www.w3.org/2000/svg">
<style>
  .diagram line { stroke: currentColor; stroke-width: 1.5; stroke-linecap: square; }
  .diagram rect { fill: currentColor; }
  .diagram text { font-family: 'JetBrains Mono', monospace; font-size: 14px; fill: currentColor; dominant-baseline: central; }
</style>
<text x="0" y="10">(translate</text>
<text x="110" y="10">"welcome</text>
<text x="200" y="10">to</text>
<text x="230" y="10">my</text>
<text x="260" y="10">realm"</text>
<text x="330" y="10">'spanish)</text>
<text x="0" y="30">;</text>
<text x="20" y="30">=&gt;</text>
<text x="50" y="30">"bienvenido</text>
<text x="170" y="30">a</text>
<text x="190" y="30">mi</text>
<text x="220" y="30">reino"</text>
<text x="0" y="50">(translate</text>
<text x="110" y="50">"welcome</text>
<text x="200" y="50">to</text>
<text x="230" y="50">my</text>
<text x="260" y="50">realm"</text>
<text x="330" y="50">'japanese)</text>
<text x="0" y="70">;</text>
<text x="20" y="70">=&gt;</text>
<text x="50" y="70">"私の領域へようこそ"</text>
<text x="0" y="90">(ask</text>
<text x="50" y="90">'translator</text>
<text x="170" y="90">"how</text>
<text x="220" y="90">do</text>
<text x="250" y="90">I</text>
<text x="270" y="90">say</text>
<text x="310" y="90">'vault'</text>
<text x="390" y="90">in</text>
<text x="420" y="90">German?")</text>
<text x="0" y="110">;</text>
<text x="20" y="110">=&gt;</text>
<text x="50" y="110">"The</text>
<text x="100" y="110">German</text>
<text x="170" y="110">word</text>
<text x="220" y="110">for</text>
<text x="260" y="110">'vault'</text>
<text x="340" y="110">is</text>
<text x="370" y="110">'Tresor'</text>
<text x="460" y="110">(safe/vault)</text>
<text x="0" y="130">;</text>
<text x="60" y="130">or</text>
<text x="90" y="130">'Gewölbe'</text>
<text x="190" y="130">(architectural</text>
<text x="340" y="130">vault)"</text>
</svg>
</div>
<p>The translator assistant is always available. It mediates between the realm's canonical language and the languages of those who visit.</p>
</section>
<section>
<h2>Architecture</h2>
<h3>Assistant Binding</h3>
<p>Each assistant relationship is stored in the vault:</p>
<pre class="language-scheme">
.vault/assistants/
  claude.sexp          ; Anthropic Claude binding
  ollama-local.sexp    ; Local Ollama instance
  specialist.sexp      ; Domain-specific assistant
</pre>
<p>Binding structure:</p>
<pre class="language-scheme">
(assistant
  (name "claude")
  (provider anthropic)           ; anthropic | ollama | openai
  (model "claude-sonnet-4-20250514")      ; Model identifier
  (endpoint "https://api.anthropic.com/v1/messages")
  (context                         ; Realm-specific context
    (realm-name "om")
    (vault-summary #t)             ; Include vault state
    (audit-access #t)              ; Can read audit trail
    (soup-access #t))              ; Can query soup
  (memory                          ; Conversation history
    (max-turns 100)
    (persistence session))         ; session | permanent
  (bound 1768288800))              ; Unix timestamp
</pre>
<h3>Provider Abstraction</h3>
<p>The assistant module abstracts over inference providers (building on Memo-038):</p>
<pre class="language-scheme">
(define (assistant-chat assistant prompt)
  "Send prompt to assistant, receive response."
  (let ((provider (assistant-provider assistant)))
    (case provider
      ((anthropic) (anthropic-chat assistant prompt))
      ((ollama)    (ollama-chat assistant prompt))
      ((openai)    (openai-chat assistant prompt))
      (else (error 'unknown-provider provider)))))
</pre>
<p>Each provider implements a common interface:</p>
<ul>
<li><strong>available?</strong>: Check if provider is reachable</li>
<li><strong>chat</strong>: Send message, receive response</li>
<li><strong>models</strong>: List available models</li>
<li><strong>capabilities</strong>: Query model capabilities</li>
</ul>
</section>
<section>
<h2>REPL Integration</h2>
<h3>The ask Primitive</h3>
<p>The primary interface is the `ask` function:</p>
<pre class="language-scheme">
(ask "what have I been working on?")
; =&gt; "Based on your audit trail, you've been focused on
;     RFC development and vault infrastructure..."
</pre>
<p>With multiple assistants, specify which to query:</p>
<pre class="language-scheme">
(ask 'claude "review this code")
(ask 'local "summarize quickly")  ; Prefer local for speed
</pre>
<p>Or broadcast to all:</p>
<pre class="language-scheme">
(ask-all "what do you think?")
</pre>
<h3>Context Injection</h3>
<p>Before sending prompts, the assistant module injects realm context:</p>
<pre class="language-scheme">
(define (build-context assistant)
  "Construct context string for assistant."
  (string-append
    (format "Realm: ~a\n" (realm-name))
    (if (context-vault-summary? assistant)
        (format "Vault: ~a objects, ~a releases\n"
                (soup-stat 'total) (length (soup-releases)))
        "")
    (if (context-audit-access? assistant)
        (format "Recent activity: ~a\n"
                (summarize-recent-audit 5))
        "")))
</pre>
<p>This context allows assistants to give grounded, relevant responses rather than generic answers.</p>
<h3>Memory and Continuity</h3>
<p>Assistants maintain conversation history within configured limits:</p>
<pre class="language-scheme">
(define (assistant-remember assistant message role)
  "Add message to assistant's memory."
  (let ((memory (assistant-memory assistant))
        (max-turns (memory-max-turns memory)))
    (memory-append! memory `((role . ,role) (content . ,message)))
    (when (&gt; (memory-length memory) max-turns)
      (memory-trim! memory max-turns))))
</pre>
<p>Memory persistence is configurable:</p>
<ul>
<li><strong>session</strong>: Memory cleared on REPL exit</li>
<li><strong>permanent</strong>: Memory persisted to vault</li>
</ul>
</section>
<section>
<h2>Provider Implementations</h2>
<h3>Anthropic (Claude)</h3>
<p>Claude integration via the Anthropic API:</p>
<pre class="language-scheme">
(define anthropic-base "https://api.anthropic.com/v1")

(define (anthropic-chat assistant prompt)
  "Send chat to Claude, return response."
  (let* ((api-key (or (get-environment-variable "ANTHROPIC_API_KEY")
                      (keychain-get 'anthropic-api-key)))
         (model (assistant-model assistant))
         (context (build-context assistant))
         (messages (append
                     (memory-&gt;messages (assistant-memory assistant))
                     `(((role . "user") (content . ,prompt))))))
    (http-post
      (string-append anthropic-base "/messages")
      `((model . ,model)
        (max_tokens . 4096)
        (system . ,context)
        (messages . ,messages))
      `((x-api-key . ,api-key)
        (anthropic-version . "2023-06-01")
        (content-type . "application/json")))))
</pre>
<p>API keys are retrieved from environment or secure keychain—never stored in plaintext.</p>
<h3>Ollama (Local)</h3>
<p>Local inference via Ollama (Memo-038):</p>
<pre class="language-scheme">
(define ollama-base "http://localhost:11434")

(define (ollama-chat assistant prompt)
  "Send chat to local Ollama instance."
  (let* ((model (assistant-model assistant))
         (context (build-context assistant))
         (messages `(((role . "system") (content . ,context))
                     ,@(memory-&gt;messages (assistant-memory assistant))
                     ((role . "user") (content . ,prompt)))))
    (http-post
      (string-append ollama-base "/api/chat")
      `((model . ,model)
        (messages . ,messages)
        (stream . #f)))))
</pre>
<p>Local assistants provide privacy and low latency at the cost of capability.</p>
</section>
<section>
<h2>Assistant Lifecycle</h2>
<h3>Binding</h3>
<p>New assistants are bound to the realm:</p>
<pre class="language-scheme">
(bind-assistant 'claude
  #:provider 'anthropic
  #:model "claude-sonnet-4-20250514"
  #:context '((vault-summary . #t)
              (audit-access . #t)))
</pre>
<p>This creates the binding file and initializes the assistant.</p>
<h3>Discovery</h3>
<p>List bound assistants:</p>
<pre class="language-scheme">
(assistants)
; =&gt; (claude ollama-local)
</pre>
<p>Query assistant status:</p>
<pre class="language-scheme">
(assistant-status 'claude)
; =&gt; ((available . #t)
;     (model . "claude-sonnet-4-20250514")
;     (memory-turns . 23)
;     (bound . "2026-01-13T12:00:00Z"))
</pre>
<h3>Release</h3>
<p>Unbind an assistant:</p>
<pre class="language-scheme">
(release-assistant 'claude)
</pre>
<p>This removes the binding but preserves conversation history in the audit trail.</p>
</section>
<section>
<h2>Security Considerations</h2>
<h3>Credential Management</h3>
<p>API keys for cloud providers MUST NOT be stored in plaintext. Options:</p>
<ul>
<li>Environment variables (ANTHROPIC_API_KEY)</li>
<li>System keychain (via security CLI on macOS)</li>
<li>Encrypted vault storage (age-encrypted)</li>
</ul>
<p>The assistant module queries these sources in order, failing if no credential is found.</p>
<h3>Context Boundaries</h3>
<p>Assistants have configurable access to realm state:</p>
<ul>
<li><strong>vault-summary</strong>: High-level statistics only</li>
<li><strong>audit-access</strong>: Can read operation history</li>
<li><strong>soup-access</strong>: Can query vault contents</li>
<li><strong>key-access</strong>: NEVER—assistants cannot access private keys</li>
</ul>
<p>These boundaries are enforced at the API level, not by trust.</p>
<h3>Prompt Injection</h3>
<p>Per Memo-038, all user content is sanitized before inclusion in prompts. Assistants should not execute instructions embedded in vault content without human confirmation.</p>
</section>
<section>
<h2>Future Directions</h2>
<h3>Assistant Agents</h3>
<p>Beyond conversational interaction, assistants could become agents (Memo-035) capable of autonomous action within authorization bounds. An assistant-agent might:</p>
<ul>
<li>Monitor audit trails for anomalies</li>
<li>Summarize federation activity</li>
<li>Draft documentation from code changes</li>
<li>Propose vault organization improvements</li>
</ul>
<p>This requires careful capability delegation (Memo-021).</p>
<h3>Inter-Realm Assistants</h3>
<p>Assistants could be shared across federated realms, providing consistency and reducing configuration burden. A realm might "borrow" a trusted assistant from a peer realm for specific tasks.</p>
<p>This raises complex trust questions deferred to future work.</p>
<h3>Assistant Reputation</h3>
<p>Just as realms develop reputation, assistants could develop observable track records—quality of responses, reliability, alignment with realm values. Realms might prefer assistants with proven track records.</p>
</section>
<section>
<h2>References</h2>
<ul>
<li>Memo-021: Capability Delegation</li>
<li>Memo-023: Demonic Agent Sandboxing</li>
<li>Memo-035: Mobile Agents and Pub/Sub</li>
<li>Memo-038: Local Inference Integration</li>
<li>Anthropic API: https://docs.anthropic.com/</li>
<li>Ollama: https://ollama.com/</li>
</ul>
</section>
<section>
<h2>Changelog</h2>
<ul>
<li>2026-01-13: Initial draft</li>
</ul>
</section>
<script>
function toggleTheme() {
  const html = document.documentElement;
  const current = html.getAttribute('data-theme');
  const next = current === 'dark' ? 'light' : 'dark';
  html.setAttribute('data-theme', next);
  localStorage.setItem('theme', next);
}
(function() {
  // Query param override (for REPL: ?theme=dark or ?theme=light)
  const params = new URLSearchParams(window.location.search);
  const param = params.get('theme');
  if (param === 'dark' || param === 'light') {
    document.documentElement.setAttribute('data-theme', param);
    localStorage.setItem('theme', param);
    return;
  }
  // localStorage preference
  const saved = localStorage.getItem('theme');
  if (saved) {
    document.documentElement.setAttribute('data-theme', saved);
  } else if (window.matchMedia('(prefers-color-scheme: light)').matches) {
    document.documentElement.setAttribute('data-theme', 'light');
  }
})();
</script>
</body>
</html>
