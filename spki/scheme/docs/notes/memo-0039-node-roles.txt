Memo 0039: Realm Roles and Capabilities


------------------------------------------------------------------------

------------------------------------------------------------------------
ABSTRACT
------------------------------------------------------------------------

This Memo defines functional roles for nodes in a Library of Cyberspace
confederation based on compute, storage, network, and security
capabilities. Roles determine what operations a node can perform and how
it participates in the distributed system.


------------------------------------------------------------------------
TERMINOLOGY
------------------------------------------------------------------------

Realm: A node's place in cyberspace. A realm encompasses: - The node's
vault (local content-addressed object store) - The node's principal
(Ed25519 identity) - The node's capabilities (hardware, network,
security) - The node's objects (what it stores and serves)

A realm is local-first and sovereign. The node controls what to share,
who to trust, what to replicate. When nodes federate, their realms
overlap - objects flow between them according to trust relationships.

The hardware manifest stored at .vault/node-hardware declares what kind
of place this realm occupies in cyberspace.


------------------------------------------------------------------------
MOTIVATION
------------------------------------------------------------------------

Memo-010 (Federation Protocol) defines trust relationships between peers
(publisher, subscriber, peer). However, it does not address functional
capabilities - what operations each node can actually perform based on
its hardware and network constraints.

A Raspberry Pi on a solar-powered satellite uplink has different
capabilities than a rack-mounted server in a datacenter. The system
should:

  * Self-assess - Nodes should know their own capabilities
  * Declare - Nodes should advertise their role to peers
  * Adapt - Operations should degrade gracefully based on available roles
  * Persist - Role assignments should survive restarts

Automatic role detection enables heterogeneous hardware to participate
appropriately without manual configuration.

Without explicit role management, the system either assumes all nodes
are equal or requires manual configuration; neither scales.


------------------------------------------------------------------------
NODE ROLES
------------------------------------------------------------------------


Role Hierarchy
--------------


                        ┌─────────────┐
                        │ COORDINATOR │  Byzantine consensus, threshold signing
                        │   (rare)    │  Always-on, high compute
                        └──────┬──────┘
                               │
                  ┌────────────┼────────────┐
                  ▼            ▼            ▼
           ┌───────────┐ ┌───────────┐ ┌───────────┐
           │   FULL    │ │  WITNESS  │ │ ARCHIVER  │
           │   NODE    │ │           │ │           │
           └─────┬─────┘ └───────────┘ └───────────┘
                 │
                 ▼
           ┌───────────┐
           │   EDGE    │  Read-only, mobile, intermittent
           └───────────┘


Role Definitions
----------------


  Role          Compute   Storage   Network        Operations                                             
  coordinator   High      Medium    Always-on      Byzantine consensus, threshold signing, key ceremony   
  full          Medium    High      Reliable       All vault operations, replication origin               
  witness       Low       High      Intermittent   Passive storage, hash verification, audit              
  archiver      Low       Maximum   Batch          Cold storage, offline preservation                     
  edge          Minimal   Minimal   Sporadic       Read-only sync, mobile access                          


Capability Requirements
-----------------------


    (node-role-capabilities
      (coordinator
        (compute    (min-cores 4) (min-ram-gb 8))
        (storage    (min-gb 100) (type ssd))
        (network    (uptime 0.99) (latency-ms 50))
        (security   (hsm optional) (secure-enclave optional)))
      (full
        (compute    (min-cores 2) (min-ram-gb 4))
        (storage    (min-gb 500) (type any))
        (network    (uptime 0.95) (latency-ms 200))
        (security   (signing-key required)))
      (witness
        (compute    (min-cores 1) (min-ram-gb 1))
        (storage    (min-gb 100) (type any))
        (network    (uptime 0.50) (latency-ms 1000))
        (security   (verify-key required)))
      (archiver
        (compute    (min-cores 1) (min-ram-gb 512mb))
        (storage    (min-gb 1000) (type cold))
        (network    (uptime 0.10) (batch-ok #t))
        (security   (verify-key required) (offline-ok #t)))
      (edge
        (compute    (min-cores 1) (min-ram-gb 256mb))
        (storage    (min-gb 1) (type any))
        (network    (uptime 0.01) (latency-ms 5000))
        (security   (read-only #t))))


------------------------------------------------------------------------
ROLE DETECTION
------------------------------------------------------------------------


Automatic Probing
-----------------


    (define (node-probe-capabilities)
      "Probe local system capabilities"
      `((compute
         (cores ,(get-cpu-cores))
         (ram-gb ,(get-ram-gb))
         (load-avg ,(get-load-average)))
        (storage
         (available-gb ,(get-available-storage))
         (type ,(detect-storage-type)))
        (network
         (latency-ms ,(probe-network-latency))
         (bandwidth-mbps ,(estimate-bandwidth))
         (type ,(detect-network-type)))  ; ethernet, wifi, cellular, satellite
        (security
         (signing-key ,(has-signing-key?))
         (verify-key ,(has-verify-key?))
         (hsm ,(has-hsm?)))))


Role Assignment
---------------


    (define (node-assign-role capabilities)
      "Assign role based on probed capabilities"
      (let ((compute (assq 'compute capabilities))
            (storage (assq 'storage capabilities))
            (network (assq 'network capabilities)))
        (cond
         ;; Coordinator: high everything
         ((and (>= (get-cores compute) 4)
               (>= (get-ram compute) 8)
               (<= (get-latency network) 50))
          'coordinator)
         ;; Full node: medium compute, high storage
         ((and (>= (get-cores compute) 2)
               (>= (get-storage storage) 500))
          'full)
         ;; Archiver: low compute, massive storage, batch network
         ((and (>= (get-storage storage) 1000)
               (eq? (get-network-type network) 'batch))
          'archiver)
         ;; Witness: low compute, decent storage
         ((>= (get-storage storage) 100)
          'witness)
         ;; Edge: everything else
         (else 'edge))))


------------------------------------------------------------------------
ROLE DECLARATION
------------------------------------------------------------------------


Local Configuration
-------------------


    ;; ~/.cyberspace/node-role
    (node-config
      (role witness)                    ; Declared role
      (auto-detect #f)                  ; Don't override with probed
      (capabilities                     ; Known constraints
        (network (type satellite)
                 (latency-ms 600)
                 (bandwidth-mbps 100))))


Role Announcement
-----------------


    (define (node-announce-role)
      "Announce role to federation peers"
      (let ((role (node-current-role))
            (caps (node-probe-capabilities))
            (key (vault-config 'signing-key)))
        (when key
          (let ((announcement
                 `(node-role-announcement
                   (principal ,(get-vault-principal key))
                   (role ,role)
                   (capabilities ,caps)
                   (timestamp ,(current-seconds)))))
            ;; Sign and broadcast
            (federation-broadcast
             (sign-announcement announcement key))))))


------------------------------------------------------------------------
ROLE-BASED OPERATION CONSTRAINTS
------------------------------------------------------------------------


Operation Matrix
----------------


  Operation          coordinator   full   witness   archiver   edge   
  seal-commit        
  seal-release       
  seal-archive       
  seal-restore       
  seal-publish       
  seal-subscribe     
  seal-synchronize   
  seal-verify        
  threshold-sign     
  byzantine-vote     
  key-ceremony       
  audit-append       
  audit-verify       


Graceful Degradation
--------------------


    (define (node-can-perform? operation)
      "Check if current role permits operation"
      (let ((role (node-current-role))
            (required (operation-required-role operation)))
        (role-permits? role required)))
    (define (role-permits? actual required)
      "Check role hierarchy"
      (let ((hierarchy '(coordinator full witness archiver edge)))
        (<= (list-index hierarchy actual)
            (list-index hierarchy required))))


------------------------------------------------------------------------
STARLINK CONSIDERATIONS
------------------------------------------------------------------------

Per Memo-016, the system is optimized for satellite links:


    (node-config
      (role witness)
      (network
        (type satellite)
        (provider starlink)
        (characteristics
          (latency-ms 20-40)           ; Low-earth orbit
          (bandwidth-mbps 100-200)     ; Bursty
          (jitter high)                ; Variable
          (uptime 0.95)                ; Weather dependent
          (data-cap none))))           ; Unlimited for now
    ;; Satellite-optimized behavior
    (define satellite-mode
      '((batch-sync #t)                ; Aggregate operations
        (lazy-pull #t)                 ; Don't fetch eagerly
        (compress-always #t)           ; Minimize transfer
        (retry-aggressive #t)          ; Handle drops
        (heartbeat-interval 300)))     ; 5 min, not seconds


Role Implications for Satellite Nodes
-------------------------------------

- coordinator: Generally NOT suitable for satellite (latency too
variable for consensus) - full: Marginal (can work with lazy clustering)
- witness: IDEAL (passive, tolerates latency) - archiver: IDEAL (batch
operations) - edge: IDEAL (intermittent by design)


------------------------------------------------------------------------
IMPLEMENTATION
------------------------------------------------------------------------


REPL Commands
-------------


    ;; Probe and display capabilities
    (node-probe)
    ;; Show current role
    (node-role)
    ;; Set role explicitly
    (node-role 'witness)
    ;; Check if operation permitted
    (node-can? 'threshold-sign)
    ;; Announce role to peers
    (node-announce)


Persistence
-----------

Role configuration stored in the realm:


    ~/.cyberspace/node-role      ; User override (global)
    .vault/node-role             ; Realm-specific role
    .vault/node-hardware         ; Hardware manifest (auto-refreshed)

The hardware manifest is automatically updated on REPL startup,
declaring the realm's capabilities to federated peers.


Audit Trail
-----------

Role changes are auditable events:


    (audit-entry
      (type node-role-change)
      (timestamp 1736280000)
      (from edge)
      (to witness)
      (reason "Storage expanded")
      (actor #${principal}))


------------------------------------------------------------------------
SECURITY CONSIDERATIONS
------------------------------------------------------------------------


Role Spoofing
-------------

A node could claim a higher role than its capabilities warrant.
Mitigations:

  * Capability proofs: Require benchmark results
  * Peer validation: Other nodes can challenge claims
  * Reputation: Track role fulfillment history
  * Threshold trust: Multiple witnesses needed

These mitigations layer defense in depth; no single spoofing technique
defeats all of them.


Role Downgrade Attacks
----------------------

An attacker could force nodes to operate at lower roles:

  * Signed role declarations: Can't forge
  * Local override: Node controls own role
  * Audit trail: Role changes are logged

A node's sovereignty over its own role prevents external actors from
dictating its participation level.


------------------------------------------------------------------------
MEMBERSHIP LIFECYCLE
------------------------------------------------------------------------

Roles define what a node can do; membership defines who belongs. This
section specifies the full lifecycle: enrollment, persistence, voluntary
departure, and involuntary removal.


Join Policy
-----------

A realm's join policy determines how new members are admitted. Four
policies, from most to least permissive:


  Policy      Description                               When                                         
  open        Any node may join; master auto-approves   Development, testing, personal realms        
  sponsored   Existing member vouches for joiner        Default for small realms (2-10 nodes)        
  voted       N-of-M existing members must approve      Production realms, high-trust environments   
  closed      No new members accepted                   Frozen realms, archival configurations       

The policy is a realm-level setting, stored in realm state and enforced
by the join listener.


    (realm-state
      (version 1)
      (master fluffy)
      (join-policy sponsored)    ; open | sponsored | voted | closed
      (vote-threshold (2 3))     ; 2-of-3 required (voted policy only)
      ...)

Open policy is the current default. The join listener accepts any
well-formed join request and issues a certificate. This is correct for
the current two-node development scenario but must evolve as realms
grow.


Sponsored Enrollment
--------------------

Under the sponsored policy, the sponsoring member's identity is recorded
in the enrollment certificate:


    (signed-enrollment-cert
      (spki-cert
        (issuer (principal ed25519:...))
        (subject (name new-node) (principal ed25519:...))
        (role full)
        (sponsor fluffy)             ; who vouched
        (validity (not-before ...) (not-after ...))))
      (signature ...))

The sponsor field creates an accountability chain. If a sponsored node
misbehaves, the sponsor's judgment is part of the audit record.


Voted Enrollment
----------------

Under the voted policy, a join request enters a pending queue. Existing
members vote to approve or reject.


    ;; Pending join request (stored in *pending-proposals*)
    (pending-join
      (name starlight)
      (pubkey #${...})
      (hardware (introspection ...))
      (proposed-by fluffy)
      (proposed-at 1770583600)
      (votes ((fluffy . approve)
              (luna . approve)))
      (threshold (2 3))              ; need 2-of-3
      (status pending))              ; pending | approved | rejected | expired

When the threshold is met, the proposing member (or any approver) issues
the enrollment certificate. Votes are gossiped so all members converge
on the same decision.

Pending proposals expire after a configurable timeout (default: 7 days).
Expired proposals are garbage-collected and the joiner must re-request.


Enrollment Persistence
----------------------

After successful enrollment (by any policy), three artifacts are
persisted to the vault:


    .vault/
      certs/membership.sexp           ; signed enrollment certificate
      keystore/
        enrollment.pub                ; Ed25519 public key (plaintext)
        enrollment.key                ; Ed25519 private key (plaintext)
      realm-state.sexp                ; master, role, members, timestamp

On restart, the system checks all three. If any is missing or invalid,
the node falls back to fresh auto-enrollment. This three-point check
prevents a node from operating with stale identity material.

Hardware capabilities and scaling factors are NOT persisted. They are
recomputed from fresh introspection on every startup, ensuring the
node's declared capabilities always match reality.


------------------------------------------------------------------------
LEAVING A REALM
------------------------------------------------------------------------

A node may voluntarily depart a realm. Departure is clean: the node
revokes its own membership, notifies peers, and returns to the
Wilderness.


Voluntary Departure
-------------------


    (define (leave-realm)
      "Voluntarily depart the realm. Clean exit."
      ;; 1. Notify peers (gossip departure)
      ;; 2. Revoke local membership cert
      ;; 3. Delete realm-state.sexp
      ;; 4. Delete enrollment keypair
      ;; 5. Stop join listener
      ;; 6. Unregister from Bonjour
      ;; 7. Reset in-memory state
      ;; Node returns to Wilderness
      ...)

Steps 1-6 are idempotent. A crashed node that restarts after partial
departure will detect the missing files and fall through to fresh
enrollment, achieving the same end state.


Member List Update
------------------

When a node departs, the remaining members must update their member
lists. The departure is gossiped as a membership event:


    (membership-event
      (type departure)
      (node starlight)
      (timestamp 1770583600)
      (reason voluntary)             ; voluntary | timeout | disbarred
      (signed-by starlight))

On receiving a departure event, each member removes the node from its
local member list and recomputes scaling factors. If the departing node
was master, the remaining members trigger a new election.


Master Departure
----------------

If the master departs, the realm needs a new one. The remaining members
hold a capability-based election (same as initial enrollment). The most
capable remaining node becomes master.

If no members remain, the realm ceases to exist. Its artifacts persist
in vaults but no active realm operates.


------------------------------------------------------------------------
DISBARMENT
------------------------------------------------------------------------

Involuntary removal of a malicious or compromised node. Unlike voluntary
departure, the node does not cooperate.


Grounds for Disbarment
----------------------

  * Certificate compromise: Private key leaked or stolen
  * Byzantine behavior: Node issues conflicting statements
  * Resource abuse: Excessive storage, bandwidth, or compute consumption
  * Protocol violation: Malformed messages, replay attacks

Disbarment is a serious action. The bar is high because false positives
destroy trust in the system.


Disbarment Protocol
-------------------

Disbarment requires a vote under the realm's join policy (even if the
join policy is 'open', disbarment always requires a vote):


    ;; Disbarment proposal
    (pending-disbar
      (name compromised-node)
      (proposed-by fluffy)
      (proposed-at 1770583600)
      (reason "Certificate compromise detected")
      (evidence (audit-ref "hash-of-evidence"))
      (votes ((fluffy . disbar)
              (luna . disbar)))
      (threshold (2 3))
      (status pending))

When the threshold is met:

  * The node's membership certificate is revoked (added to a revocation list)
  * The node is removed from all member lists
  * The revocation is gossiped to all members
  * The node's Bonjour registration is ignored by members
  * Scaling factors are recomputed without the disbarred node


Certificate Revocation
----------------------

Revoked certificates are stored in a revocation list that is gossiped
alongside membership events:


    (revocation-list
      (version 1)
      (entries
        ((principal ed25519:abc123...)
         (revoked-at 1770583600)
         (reason "Byzantine behavior")
         (revoked-by (fluffy luna)))))

Any node encountering a revoked certificate rejects it, even if the
certificate is otherwise valid. The revocation list is append-only and
signed by the revoking quorum.


Disbarred Node Behavior
-----------------------

A disbarred node finds itself unable to participate:

  * Join requests are rejected (pubkey is on revocation list)
  * Gossip messages from the node are dropped
  * The node can still operate locally but cannot federate

The node effectively returns to the Wilderness but with a tainted
identity. It must generate new keys to re-enroll, and even then, the
voted policy provides a gate.


------------------------------------------------------------------------
PENDING JOINS QUEUE
------------------------------------------------------------------------

The pending proposals queue (*pending-proposals*) tracks join and
disbarment votes in progress.


Queue Structure
---------------


    (define *pending-proposals* '())
    ;; Each proposal:
    (proposal
      (id "hash-of-proposal")
      (type join)                    ; join | disbar
      (subject node-name)
      (proposed-by proposer-name)
      (proposed-at timestamp)
      (votes ())                     ; ((name . vote) ...)
      (threshold (n m))              ; n-of-m required
      (expires (+ proposed-at 604800))  ; 7 days
      (status pending))              ; pending | approved | rejected | expired


Queue Operations
----------------


    ;; Propose a new member
    (propose-join 'new-node pubkey hardware)
    ;; Vote on a pending proposal
    (vote-proposal proposal-id 'approve)  ; or 'reject
    ;; List pending proposals
    (pending)
    ;; Proposals are gossiped between members
    ;; Votes are gossiped as they arrive
    ;; Threshold check happens on every vote receipt


Consistency
-----------

Proposals and votes are gossiped, so all members eventually see the same
state. Because votes are idempotent (a member can only vote once per
proposal), convergence is guaranteed regardless of message ordering.

In the event of a network partition, each partition may independently
reach a threshold if enough members are present. When the partition
heals, the gossiped results converge. If conflicting decisions were made
(one partition approved, another rejected), the earlier timestamp wins.


------------------------------------------------------------------------
VOTING PROTOCOL
------------------------------------------------------------------------

Membership votes use the quorum protocol defined in Memo-038. The
specific application to membership decisions:


Simple Majority
---------------

For small realms (2-5 members), a simple majority suffices. Votes are
open (not encrypted) since the social cost of disagreement is low in
small groups.


    (vote-threshold
      (policy majority)
      (minimum 2))                   ; at least 2 votes regardless of realm size


N-of-M Threshold
----------------

For larger realms, an explicit threshold prevents single members from
controlling admission:


    (vote-threshold
      (policy threshold)
      (n 3)
      (m 5))                         ; 3 of 5 members must approve

The threshold is a realm-level setting. Changing the threshold itself
requires a vote at the current threshold.


Private Ballot
--------------

For sensitive decisions (especially disbarment), the homomorphic voting
protocol from Memo-038 applies. Individual votes are encrypted; only the
tally is revealed.

Private ballot is RECOMMENDED for disbarment and OPTIONAL for join
votes. The realm's join policy configuration specifies which.


------------------------------------------------------------------------
REFERENCES
------------------------------------------------------------------------

  * Memo-010: Federation Protocol
  * Memo-011: Byzantine Consensus
  * Memo-016: Lazy Clustering
  * Memo-017: Security Considerations
  * Memo-038: Quorum Protocol with Homomorphic Voting
  * Memo-050: The Wilderness


------------------------------------------------------------------------
CHANGELOG
------------------------------------------------------------------------

  * 2026-02-09: Membership lifecycle (enrollment, departure, disbarment, voting)
  * 2026-01-07: Initial draft (roles and capabilities)

------------------------------------------------------------------------
