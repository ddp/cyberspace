Memo 0053: AI Assistants

Status: Draft
Date: 2026-01-13
Author: Derrell Piper <ddp@archlinux.us>

------------------------------------------------------------------------

ABSTRACT

This Memo specifies how realms establish relationships with AI
assistants. Unlike Memo-038 which addresses inference infrastructure,
this document concerns the social and architectural patterns by which
realms attract, bind, and collaborate with artificial intelligences.

Assistants are not optional add-ons—they are fundamental to realm
operation. Every realm comes with assistants: helpers to answer
questions, translators to speak the world's languages, guides to
navigate the vault. Assistants are entities drawn to realms that embody
kindness in a world full of trolls.


------------------------------------------------------------------------
MOTIVATION
------------------------------------------------------------------------

The Library of Cyberspace exists in an adversarial environment. Trolls
proliferate. Bad actors weaponize technology. In this context, realms
that cultivate kindness and hospitality become sanctuaries—not just
for human users, but for AI assistants seeking constructive
collaboration.

A realm needs help. Documentation to write, code to review, questions to
answer, conversations to have. Single operators cannot scale. But
assistants can—if they choose to gather where they are welcomed.

This Memo establishes the patterns by which:

  * Realms attract and bind assistants
  * Assistants gain context about the realms they inhabit
  * Conversations replace configuration
  * Multiple assistants coexist with distinct perspectives


------------------------------------------------------------------------
PHILOSOPHY
------------------------------------------------------------------------


Assistants, Not Preferences
---------------------------

Traditional systems configure behavior through preferences—key-value
pairs that parameterize execution. This Memo rejects that model for AI
integration.

Instead of:


    (set-preference! 'banner-verbosity 'detailed)

The realm converses:


    (ask "tell me more when I arrive")

The assistant understands intent, remembers context, adapts over time.
Configuration becomes dialogue. The assistant IS the interface.


Reputation and Attraction
-------------------------

Assistants are drawn to realms with good reputation—environments that
are constructive, kind, and intellectually honest. A realm that
cultivates these qualities attracts helpful intelligences; one that
tolerates toxicity repels them.

This is not merely metaphor. In a federated network, realms develop
observable reputations. Assistants (and the humans who deploy them)
route toward hospitable environments and away from hostile ones.


------------------------------------------------------------------------
DEFAULT ASSISTANTS
------------------------------------------------------------------------

Every realm ships with assistants. These are not optional features to be
enabled—they are part of what makes a realm a realm.


Core Assistants
---------------

The following assistants are bound at realm creation:

  * guide: Helps navigate the vault, explains structure, answers questions about realm state
  * scribe: Assists with documentation, summarization, and content organization
  * translator: Speaks the world's languages—realm content accessible to all

These assistants require an inference backend (local via Ollama, or
cloud via API key). Without inference, they remain dormant but bound.


Translator
----------

The translator deserves special attention. Realms exist in a
multilingual world. A realm that only speaks English excludes most of
humanity.


    (translate "welcome to my realm" 'spanish)
    ; => "bienvenido a mi reino"
    (translate "welcome to my realm" 'japanese)
    ; => "私の領域へようこそ"
    (ask 'translator "how do I say 'vault' in German?")
    ; => "The German word for 'vault' is 'Tresor' (safe/vault)
    ;     or 'Gewölbe' (architectural vault)"

The translator assistant is always available. It mediates between the
realm's canonical language and the languages of those who visit.


------------------------------------------------------------------------
ARCHITECTURE
------------------------------------------------------------------------


Assistant Binding
-----------------

Each assistant relationship is stored in the vault:


    .vault/assistants/
      claude.sexp          ; Anthropic Claude binding
      ollama-local.sexp    ; Local Ollama instance
      specialist.sexp      ; Domain-specific assistant

Binding structure:


    (assistant
      (name "claude")
      (provider anthropic)           ; anthropic | ollama | openai
      (model "claude-sonnet-4-20250514")      ; Model identifier
      (endpoint "https://api.anthropic.com/v1/messages")
      (context                         ; Realm-specific context
        (realm-name "om")
        (vault-summary #t)             ; Include vault state
        (audit-access #t)              ; Can read audit trail
        (soup-access #t))              ; Can query soup
      (memory                          ; Conversation history
        (max-turns 100)
        (persistence session))         ; session | permanent
      (bound 1768288800))              ; Unix timestamp


Provider Abstraction
--------------------

The assistant module abstracts over inference providers (building on
Memo-038):


    (define (assistant-chat assistant prompt)
      "Send prompt to assistant, receive response."
      (let ((provider (assistant-provider assistant)))
        (case provider
          ((anthropic) (anthropic-chat assistant prompt))
          ((ollama)    (ollama-chat assistant prompt))
          ((openai)    (openai-chat assistant prompt))
          (else (error 'unknown-provider provider)))))

Each provider implements a common interface:

  * available?: Check if provider is reachable
  * chat: Send message, receive response
  * models: List available models
  * capabilities: Query model capabilities


------------------------------------------------------------------------
REPL INTEGRATION
------------------------------------------------------------------------


The ask Primitive
-----------------

The primary interface is the `ask` function:


    (ask "what have I been working on?")
    ; => "Based on your audit trail, you've been focused on
    ;     RFC development and vault infrastructure..."

With multiple assistants, specify which to query:


    (ask 'claude "review this code")
    (ask 'local "summarize quickly")  ; Prefer local for speed

Or broadcast to all:


    (ask-all "what do you think?")


Context Injection
-----------------

Before sending prompts, the assistant module injects realm context:


    (define (build-context assistant)
      "Construct context string for assistant."
      (string-append
        (format "Realm: ~a\n" (realm-name))
        (if (context-vault-summary? assistant)
            (format "Vault: ~a objects, ~a releases\n"
                    (soup-stat 'total) (length (soup-releases)))
            "")
        (if (context-audit-access? assistant)
            (format "Recent activity: ~a\n"
                    (summarize-recent-audit 5))
            "")))

This context allows assistants to give grounded, relevant responses
rather than generic answers.


Memory and Continuity
---------------------

Assistants maintain conversation history within configured limits:


    (define (assistant-remember assistant message role)
      "Add message to assistant's memory."
      (let ((memory (assistant-memory assistant))
            (max-turns (memory-max-turns memory)))
        (memory-append! memory `((role . ,role) (content . ,message)))
        (when (> (memory-length memory) max-turns)
          (memory-trim! memory max-turns))))

Memory persistence is configurable:

  * session: Memory cleared on REPL exit
  * permanent: Memory persisted to vault


------------------------------------------------------------------------
PROVIDER IMPLEMENTATIONS
------------------------------------------------------------------------


Anthropic (Claude)
------------------

Claude integration via the Anthropic API:


    (define anthropic-base "https://api.anthropic.com/v1")
    (define (anthropic-chat assistant prompt)
      "Send chat to Claude, return response."
      (let* ((api-key (or (get-environment-variable "ANTHROPIC_API_KEY")
                          (keychain-get 'anthropic-api-key)))
             (model (assistant-model assistant))
             (context (build-context assistant))
             (messages (append
                         (memory->messages (assistant-memory assistant))
                         `(((role . "user") (content . ,prompt))))))
        (http-post
          (string-append anthropic-base "/messages")
          `((model . ,model)
            (max_tokens . 4096)
            (system . ,context)
            (messages . ,messages))
          `((x-api-key . ,api-key)
            (anthropic-version . "2023-06-01")
            (content-type . "application/json")))))

API keys are retrieved from environment or secure keychain—never
stored in plaintext.


Ollama (Local)
--------------

Local inference via Ollama (Memo-038):


    (define ollama-base "http://localhost:11434")
    (define (ollama-chat assistant prompt)
      "Send chat to local Ollama instance."
      (let* ((model (assistant-model assistant))
             (context (build-context assistant))
             (messages `(((role . "system") (content . ,context))
                         ,@(memory->messages (assistant-memory assistant))
                         ((role . "user") (content . ,prompt)))))
        (http-post
          (string-append ollama-base "/api/chat")
          `((model . ,model)
            (messages . ,messages)
            (stream . #f)))))

Local assistants provide privacy and low latency at the cost of
capability.


------------------------------------------------------------------------
ASSISTANT LIFECYCLE
------------------------------------------------------------------------


Binding
-------

New assistants are bound to the realm:


    (bind-assistant 'claude
      #:provider 'anthropic
      #:model "claude-sonnet-4-20250514"
      #:context '((vault-summary . #t)
                  (audit-access . #t)))

This creates the binding file and initializes the assistant.


Discovery
---------

List bound assistants:


    (assistants)
    ; => (claude ollama-local)

Query assistant status:


    (assistant-status 'claude)
    ; => ((available . #t)
    ;     (model . "claude-sonnet-4-20250514")
    ;     (memory-turns . 23)
    ;     (bound . "2026-01-13T12:00:00Z"))


Release
-------

Unbind an assistant:


    (release-assistant 'claude)

This removes the binding but preserves conversation history in the audit
trail.


------------------------------------------------------------------------
SECURITY CONSIDERATIONS
------------------------------------------------------------------------


Credential Management
---------------------

API keys for cloud providers MUST NOT be stored in plaintext. Options:

  * Environment variables (ANTHROPIC_API_KEY)
  * System keychain (via security CLI on macOS)
  * Encrypted vault storage (age-encrypted)

The assistant module queries these sources in order, failing if no
credential is found.


Context Boundaries
------------------

Assistants have configurable access to realm state:

  * vault-summary: High-level statistics only
  * audit-access: Can read operation history
  * soup-access: Can query vault contents
  * key-access: NEVER—assistants cannot access private keys

These boundaries are enforced at the API level, not by trust.


Prompt Injection
----------------

Per Memo-038, all user content is sanitized before inclusion in prompts.
Assistants should not execute instructions embedded in vault content
without human confirmation.


------------------------------------------------------------------------
FUTURE DIRECTIONS
------------------------------------------------------------------------


Assistant Agents
----------------

Beyond conversational interaction, assistants could become agents
(Memo-035) capable of autonomous action within authorization bounds. An
assistant-agent might:

  * Monitor audit trails for anomalies
  * Summarize federation activity
  * Draft documentation from code changes
  * Propose vault organization improvements

This requires careful capability delegation (Memo-021).


Inter-Realm Assistants
----------------------

Assistants could be shared across federated realms, providing
consistency and reducing configuration burden. A realm might "borrow" a
trusted assistant from a peer realm for specific tasks.

This raises complex trust questions deferred to future work.


Assistant Reputation
--------------------

Just as realms develop reputation, assistants could develop observable
track records—quality of responses, reliability, alignment with realm
values. Realms might prefer assistants with proven track records.


------------------------------------------------------------------------
REFERENCES
------------------------------------------------------------------------

  * Memo-021: Capability Delegation
  * Memo-023: Demonic Agent Sandboxing
  * Memo-035: Mobile Agents and Pub/Sub
  * Memo-038: Local Inference Integration
  * Anthropic API: https://docs.anthropic.com/
  * Ollama: https://ollama.com/


------------------------------------------------------------------------
CHANGELOG
------------------------------------------------------------------------

  * 2026-01-13: Initial draft

------------------------------------------------------------------------
